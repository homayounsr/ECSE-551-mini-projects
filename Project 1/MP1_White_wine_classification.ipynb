{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8i_K-Od-SP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ae0f5a-af9a-4846-c596-745c8b7e862e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxJx_6SA-dhI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from re import X\n",
        "from random import seed\n",
        "from random import randrange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZdBamd1-l65"
      },
      "outputs": [],
      "source": [
        "#Load Data\n",
        "data= pd.read_csv('/content/gdrive/MyDrive/ECSE 551/MP1/White_wine Quality.csv')\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ5Hhq57mH-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a830c255-9d32-4aca-85d2-bc5da36ff685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Alcohol  Malic acid   Ash  Alkalinity of ash  Magnesium  Total phenols  \\\n",
            "0     0.19469     0.34932  0.07           0.082192   0.128550       0.140850   \n",
            "1     0.30088     0.20548  0.17           0.075342   0.101840       0.070423   \n",
            "2     0.30088     0.20548  0.17           0.075342   0.101840       0.070423   \n",
            "3     0.24779     0.34247  0.05           0.068493   0.093489       0.323940   \n",
            "4     0.25664     0.27397  0.42           0.095890   0.125210       0.098592   \n",
            "...       ...         ...   ...                ...        ...            ...   \n",
            "1593  0.19469     0.32192  0.10           0.054795   0.085142       0.464790   \n",
            "1594  0.18584     0.63014  0.08           0.095890   0.091820       0.253520   \n",
            "1595  0.23894     0.58904  0.05           0.082192   0.081803       0.267610   \n",
            "1596  0.47788     0.39041  0.11           0.034247   0.120200       0.098592   \n",
            "1597  0.18584     0.39726  0.08           0.195210   0.091820       0.098592   \n",
            "\n",
            "      Flavanoids  Nonflavanoid phenols  Proanthocyanins       Hue  \\\n",
            "0       0.134280               0.38371          0.57480  0.131740   \n",
            "1       0.042403               0.52311          0.43307  0.167660   \n",
            "2       0.042403               0.52311          0.43307  0.167660   \n",
            "3       0.127210               0.44241          0.53543  0.143710   \n",
            "4       0.113070               0.52311          0.66142  0.167660   \n",
            "...          ...                   ...              ...       ...   \n",
            "1593    0.166080               0.42040          0.52756  0.203590   \n",
            "1594    0.091873               0.47029          0.61417  0.143710   \n",
            "1595    0.151940               0.51211          0.44882  0.131740   \n",
            "1596    0.063604               0.41893          0.11024  0.083832   \n",
            "1597    0.035336               0.23991          0.54331  0.113770   \n",
            "\n",
            "      Class Labels  \n",
            "0                1  \n",
            "1                1  \n",
            "2                1  \n",
            "3                1  \n",
            "4                1  \n",
            "...            ...  \n",
            "1593             0  \n",
            "1594             0  \n",
            "1595             0  \n",
            "1596             0  \n",
            "1597             0  \n",
            "\n",
            "[1598 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "# Define the header labels for the predictor variables\n",
        "header_labels = [\"Alcohol\", \"Malic acid\", \"Ash\", \"Alkalinity of ash\", \"Magnesium\", \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\", \"Hue\",\"Class Labels\"]\n",
        "# Add the header labels to the DataFrame\n",
        "df.columns = header_labels\n",
        "# # Display the DataFrame\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irzn137pWq0D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "79c20f83-ea28-4251-8aaf-5b02cebbc65a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f758a52acd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "###################Step 1: Data Distribution#################\n",
        "#Class Distribution\n",
        "class_labels = df[\"Class Labels\"]\n",
        "class_label_counts = class_labels.value_counts()\n",
        "class_label_counts.plot(kind=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGCMvANTmpEz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3961e07d-1331-4541-d62b-3691b739d2dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Filter the DataFrame to only include rows with Class Labels 1 or 0\n",
        "#Class 1 = Good\n",
        "#Class 0 Bad\n",
        "class_0 = df[df['Class Labels'] == 0]\n",
        "class_1 = df[df['Class Labels'] == 1]\n",
        "# Plot the distribution of the \"Alcohol\" column for the class 1\n",
        "# Create a figure and two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "\n",
        "# Plot data1 in first subplot\n",
        "ax1.hist(class_0['Hue'], bins=20, edgecolor='k')\n",
        "ax1.set_title('Distribution of Alcohol for Class 0')\n",
        "plt.xlabel('Alcohol')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "\n",
        "# Plot data2 in second subplot\n",
        "ax2.hist(class_1['Hue'], bins=20, edgecolor='k')\n",
        "ax2.set_title('Distribution of Alcohol for Class 1')\n",
        "plt.xlabel('Alcohol')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is spliting the data. The line x = dataset[:, 0:5] is selection the features. If you want to use a specific column of feature and remove the rest of them to change the accuracy just you need to change the number this line:\n",
        "\n",
        "***Note that default setting is using all 10 features***\n",
        "\n",
        "x = dataset[:, 0:10]"
      ],
      "metadata": {
        "id": "zfhtSfpuHO95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.utils import shuffle\n",
        "# #Shuffle the dataset\n",
        "# dataset = shuffle(np.array(data))\n",
        "# #Save the shuffled dataset to a new file\n",
        "# np.savetxt('/content/gdrive/MyDrive/ECSE 551/MP1/White_wine Quality_shuffled.csv', dataset, delimiter=',')"
      ],
      "metadata": {
        "id": "EyFKhANyB76e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALk6yiiijF2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a30d34c-73a5-4af4-986c-367f76c1bfd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1598,)\n",
            "X_trian shape (1278, 9)\n",
            "X_test shape (320, 9)\n",
            "y_train shape (1278,)\n",
            "y_test shape (320,)\n",
            "[1. 1. 1. ... 0. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "#Split Data\n",
        "dataset = np.loadtxt('/content/gdrive/MyDrive/ECSE 551/MP1/White_wine Quality_shuffled.csv', delimiter=',')\n",
        "X = dataset[:, [0,1,2,3,4,5,6,7,8,9]]\n",
        "y = dataset[:, 10]\n",
        "# # Split the data into training and testing sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * X.shape[0])\n",
        "X_train, X_test = X[:train_size, :], X[train_size:, :]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "print(y.shape)\n",
        "print(\"X_trian shape\", X_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"y_test shape\", y_test.shape)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "class LogisticRegression:\n",
        "    def sigmoid(self, z):\n",
        "        sig = 1 / (1 + np.exp(-z))\n",
        "        return sig\n",
        "\n",
        "    def cost_function(self, y_train, y_predict):\n",
        "        # using negative log-likelihood to calculate the cost entropy loss function\n",
        "        cost = -np.mean(y_train*(np.log(y_predict)) - (1-y_train)*np.log(1-y_predict))\n",
        "        return cost\n",
        "\n",
        "    def gradient_descent(self, X_train, y_train, y_predict):\n",
        "        m = X_train.shape[0]\n",
        "        W_grad = (1/m)*np.dot(X_train.T, (y_predict - y_train))\n",
        "        return W_grad\n",
        "\n",
        "    def fit(self, X_train, y_train, alpha=0.01, k=50000):\n",
        "        m, n = X_train.shape\n",
        "        y_train = y_train.reshape(m,1)\n",
        "        W_fit = np.zeros((n,1))\n",
        "        loss_value = []\n",
        "\n",
        "        for i in tqdm(range(k)):\n",
        "            y_predict = self.sigmoid(np.dot(X_train, W_fit))\n",
        "            w_grad = self.gradient_descent(X_train, y_train, y_predict)\n",
        "            W_fit -= alpha*w_grad\n",
        "        loss_fuc = self.cost_function(y_train, y_predict)\n",
        "        loss_value.append(loss_fuc)\n",
        "        return W_fit, loss_value\n",
        "\n",
        "    def predict(self, X_test, W):\n",
        "        y_pred = self.sigmoid(np.dot(X_test, W))\n",
        "        predict_classes = []\n",
        "        predict_classes = [1 if prediction > 0.5 else 0 for prediction in y_pred]\n",
        "        return np.array(predict_classes)\n",
        "\n",
        "    def accu_eval(self, y_pred, y_test):\n",
        "        accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def cross_validation_split(self, X, y, folds):\n",
        "        X_split = []\n",
        "        y_split = []\n",
        "        fold_size = int(len(X) / folds)\n",
        "        for i in range(folds):\n",
        "            fold_start = i * fold_size\n",
        "            fold_end = fold_start + fold_size\n",
        "            fold_X = X[fold_start:fold_end]\n",
        "            fold_y = y[fold_start:fold_end]\n",
        "            X_split.append(fold_X)\n",
        "            y_split.append(fold_y)\n",
        "            print(fold_X.shape, fold_y.shape)\n",
        "        return np.array(X_split), np.array(y_split)\n",
        "\n",
        "    def k_fold_cross_validation(self, X, y, k=10):\n",
        "        folds = self.cross_validation_split(X, y, k)\n",
        "        X_folds = folds[0]\n",
        "        y_folds = folds[1]\n",
        "        indices = np.arange(k)\n",
        "        accuracy = 0\n",
        "\n",
        "        # exclude index fold\n",
        "        for index in range(k):\n",
        "          #spliting data\n",
        "          X_train = np.concatenate(X_folds[indices!= index])\n",
        "          Y_train = np.concatenate(y_folds[indices!= index])   \n",
        "          X_test = X_folds[index]\n",
        "          Y_test = y_folds[index]\n",
        "          #training\n",
        "          W_fit,loss_value = self.fit(X_train, Y_train)\n",
        "          print(f\"Loss value for {index+1}-fold is : {loss_value}\")\n",
        "          #testing\n",
        "          y_pred = self.predict(X_test, W_fit)\n",
        "          #accuracy\n",
        "          fold_accuracy= self.accu_eval(y_pred, Y_test)\n",
        "          accuracy += fold_accuracy\n",
        "          print(f\"accuracy for {index+1}-fold is {fold_accuracy}\")\n",
        "        average_acc = accuracy / k\n",
        "        print(average_acc)\n",
        "        return W_fit\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uL-MNdKN-UbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMvaEe1sIb3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56da764a-3740-4358-957b-6c848db5b8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n",
            "(127, 9) (127,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:06<00:00, 7941.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 1-fold is : [-0.007200636067589237]\n",
            "accuracy for 1-fold is 0.6692913385826772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:05<00:00, 9809.60it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 2-fold is : [-0.011416857859177633]\n",
            "accuracy for 2-fold is 0.7952755905511811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:03<00:00, 12537.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 3-fold is : [-0.00782548634925087]\n",
            "accuracy for 3-fold is 0.7086614173228346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:05<00:00, 9940.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 4-fold is : [-0.009049720537633518]\n",
            "accuracy for 4-fold is 0.7559055118110236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:05<00:00, 8940.20it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 5-fold is : [-0.008585660399867273]\n",
            "accuracy for 5-fold is 0.6220472440944882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:04<00:00, 12313.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 6-fold is : [-0.004055652283543107]\n",
            "accuracy for 6-fold is 0.7637795275590551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:04<00:00, 10811.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 7-fold is : [-0.010118126093446438]\n",
            "accuracy for 7-fold is 0.7244094488188977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:06<00:00, 7747.20it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 8-fold is : [-0.005413426481023809]\n",
            "accuracy for 8-fold is 0.7795275590551181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:04<00:00, 12464.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 9-fold is : [-0.005594547403887235]\n",
            "accuracy for 9-fold is 0.7401574803149606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:04<00:00, 12393.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value for 10-fold is : [-0.010301303032913817]\n",
            "accuracy for 10-fold is 0.7086614173228346\n",
            "0.7267716535433071\n",
            "[[ 4.58787414]\n",
            " [-3.63675448]\n",
            " [ 2.61480523]\n",
            " [-2.85632809]\n",
            " [ 1.28532187]\n",
            " [-4.83664877]\n",
            " [-4.671045  ]\n",
            " [ 3.43678606]\n",
            " [ 4.94541626]]\n",
            "Accuracy is: 0.78125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "logreg = LogisticRegression()\n",
        "W_fit = logreg.k_fold_cross_validation(X_train, y_train)\n",
        "print(W_fit)\n",
        "\n",
        "y_predict = logreg.predict(X_test,W_fit)\n",
        "acc = logreg.accu_eval(y_predict, y_test)\n",
        "print(f\"Accuracy is: {acc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}